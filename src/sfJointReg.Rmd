---
title: "joint structural and functional registration with antsr"
author: "Brian B. Avants et al."
date: "5/30/2018"
output: html_document
---

```{r setup, include=FALSE}
library(ANTsR)
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

Human connectome project data.

Preprocessing steps involved ( at this instructional level ) for each subject:

1. preprocess fmri
    * distortion correction
    * average bold
    * motion correction
    * rigid map to t1

2. preprocess t1
    * crude brain extraction
    * segmentation
    * map to template
    
3. extract relevant networks
    * default mode
    * motor 
    
4. perform a joint structural / functional registration between these subjects.

##  IO and modalities

```{r io}
rdir = "/Users/stnava/code/structuralFunctionalJointRegistration/"
if ( ! exists("id") ) id = '3026'
if ( ! exists("id") ) id = '2001'
# collect image data
# data/LS2001/unprocessed/3T/T1w_MPR1/LS2001_3T_T1w_MPR1_gdc.nii.gz
t1fn = paste0( rdir, 'data/LS',id, "/unprocessed/3T/T1w_MPR1/LS",id,"_3T_T1w_MPR1_gdc.nii.gz")
# now the bold data
boldfnsL = Sys.glob( paste0( rdir, 'data/LS',id, "/LS", id, "fmri/unprocessed/3T/rfMRI_REST1_*/*REST1_LR_gdc.nii.gz" ) )
boldfnsR = Sys.glob( paste0( rdir, 'data/LS',id, "/LS", id, "fmri/unprocessed/3T/rfMRI_REST1_*/*REST1_RL_gdc.nii.gz" ) )
# get the ref data
reffns = Sys.glob( paste0( rdir, 'data/LS',id, "/LS", id, "fmri/unprocessed/3T/rfMRI_REST1_*/*SBRef_gdc.nii.gz" ) )
```

##  Distortion correction (without a field map)

Let us first "undistort"

```{r}
if ( ! exists( "und" ) ) {
  i1 = antsImageRead( reffns[1] )
  i2 = antsImageRead( reffns[2] )
  und = buildTemplate( i1, list( i1, i2 ), "SyN" )
  } 
t1 = antsImageRead( t1fn ) %>% n3BiasFieldCorrection( 8 ) %>%
  n3BiasFieldCorrection( 4 )
bmask = getMask( und, lowThresh = mean( und ) * 0.75, Inf, 3 ) %>% iMath("FillHoles")
# this is a fragile approach - not really recommended - but it is quick
t1mask = getMask( t1, lowThresh = mean( t1 ) * 1.1, Inf, 5 ) %>% iMath("FillHoles")
t1rig = antsRegistration( und * bmask, t1 * t1mask, "BOLDRigid" )
t1reg = antsRegistration( und * bmask, t1 * t1mask, "SyNOnly", initialTransform = t1rig$fwd, 
          synMetric = 'CC', synSampling = 2, regIterations = c(5) )
###########################
```

These are the original LR and RL images.

```{r vizdiststuff}
print(id)
plot( i1,  axis = 3 )
plot( i2,  axis = 3 )
```

This is the result of mapping them together with an averaging transform.

```{r vizdiststuff2}
plot( und,  axis = 3 )
```

The distortion to the T1 is greatly reduced.

## Brain masking

Use the BOLD mask to extract the brain from the t1 (for expedience, usually we 
would have run `antsCorticalThickness` already.)

```{r}
t1maskFromBold = antsApplyTransforms( t1, bmask, t1reg$invtransforms, 
                                      interpolator = 'nearestNeighbor' )
t1 = n4BiasFieldCorrection( t1, t1mask, 8 ) %>%
  n4BiasFieldCorrection( t1mask, 4 )
bmask =  antsApplyTransforms( und, t1mask, t1reg$fwdtransforms, 
  interpolator = 'nearestNeighbor' ) %>% morphology("close",3)
ofn = paste0( rdir, "features/LS", id, '_mask.nii.gz' )
antsImageWrite( bmask, ofn )
t1toBOLD = antsApplyTransforms( und, t1, t1reg$fwdtransforms )
ofn = paste0( rdir, "features/LS", id, '_t1ToBold.nii.gz' )
antsImageWrite( t1toBOLD, ofn )
plot( t1, t1mask, alpha = 0.5, axis = 3 )
############################
```

here we might repeat the registration process -- *if we trust* the masks

Exercise:  Try it yourself.


## Tissue segmentation

Now we can segment the T1.

```{r segt1}
# a simple method
################################################
if ( ! exists( "t1seg" ) ) {
  qt1 = iMath( t1, "TruncateIntensity", 0, 0.95 )
  t1seg = kmeansSegmentation( qt1, 3, t1mask, 0.2 ) 
  volumes = labelStats( t1seg$segmentation, t1seg$segmentation )
  rownames( volumes ) = c("background",'csf', 'gm', 'wm' )
  volumes$NormVolume = volumes$Volume / sum( volumes$Volume[-1])
  pander::pander( volumes[ , c("LabelValue","Volume","NormVolume")] )

  # if we look and realize this is not good - fix & redo - caused by local hyperintensity
  if ( volumes["wm","NormVolume"] < 0.2 ) {
    t1mask2 = t1mask * thresholdImage( t1seg$segmentation, 1, 2 )
    t1seg = kmeansSegmentation( t1, 3, t1mask2, 0.1 ) 
    }
}
plot( t1, t1seg$segmentation, axis = 3, window.overlay=c(0,3) )
boldseg = antsApplyTransforms( und, t1seg$segmentation, t1reg$fwdtransforms, 
                               interpolator = 'nearestNeighbor' )
plot(und,boldseg,axis=3,alpha=0.5)
########################################
```


## Template mapping

* include prior information e.g. from meta-analysis or anatomy

```{r totemplate}
if ( ! exists( "treg" ) ) {
  data( "powers_areal_mni_itk" )
  myvoxes = 1:nrow( powers_areal_mni_itk )
  anat = powers_areal_mni_itk$Anatomy[myvoxes]
  syst = powers_areal_mni_itk$SystemName[myvoxes]
  Brod = powers_areal_mni_itk$Brodmann[myvoxes]
  xAAL  = powers_areal_mni_itk$AAL[myvoxes]
  if ( ! exists( "ch2" ) )
    ch2 = antsImageRead( getANTsRData( "ch2" ) )
  treg = antsRegistration( t1 * t1mask, ch2, 'SyN' )
}
concatx2 = c( treg$invtransforms, t1reg$invtransforms )
pts2bold = antsApplyTransformsToPoints( 3, powers_areal_mni_itk, concatx2, 
                                        whichtoinvert = c( T, F, T, F ) )
ptImg = makePointsImage( pts2bold, bmask, radius = 3 )
plot( und, ptImg, axis=3, window.overlay = range( ptImg ) )
bold2ch2 = antsApplyTransforms( ch2, und,  concatx2, 
      whichtoinvert = c( T, F, T, F ) )
# check the composite output
plot( bold2ch2 , axis=3 )
###########################################################
```


# Extracting canonical functional network maps


## preprocessing

back to the fmri ...

    * undistort
    * motion correction

then we will be ready for first-level analysis ...

```{r motion}
if ( ! exists( "motcorr" ) ) {
  bold = antsImageRead( boldfnsR )
  avgBold = getAverageOfTimeSeries( bold )
  # map to und 
  boldUndTX = antsRegistration( und, avgBold, "SyN", regIterations = c(20,10), 
                                 synMetric = "CC", synSampling = 2, verbose = F )
  boldUndTS = antsApplyTransforms( und, bold, boldUndTX$fwd, imagetype = 3  )
  avgBold = getAverageOfTimeSeries( boldUndTS )
  motcorr = antsrMotionCalculation( boldUndTS, verbose = F, typeofTransform = 'Rigid' )

  boldL = antsImageRead( boldfnsL )
  avgBoldL = getAverageOfTimeSeries( boldL )
  boldUndTXL = antsRegistration( und, avgBoldL, "SyN", regIterations = c(20,10), 
                                 synMetric = "CC", synSampling = 2, verbose = F )
  boldUndTSL = antsApplyTransforms( und, boldL, boldUndTXL$fwd, imagetype = 3, verbose=TRUE  )
  avgBoldL = getAverageOfTimeSeries( boldUndTSL )
  motcorrL = antsrMotionCalculation( boldUndTSL, fixed=avgBold, mask = motcorr$moco_mask,
    verbose = T, typeofTransform = 'Rigid' )
  
  # bind the two runs
  # newmo = iBind( motcorr$moco_img, motcorrL$moco_img, along = 4 )
  }
plot( ts( motcorr$fd$MeanDisplacement ) )
print( names( motcorr ) )
````

### trim the bold time series for "good" time points

* trim the first $k$ time points

* trim the high motion time points and their $k$ neighbors

We can then perform regression only in the "good" time points.

Or we can impute / interpolate ( see the RestingBold article/vignette in ANTsR documentation ).

## network modeling

now we can do some additional level-one analysis to extract relevant networks.

    * default mode
    * motor 

```{r denoise}
# use tissue segmentation to guide compcor 
# FIXME - provide reference for this approach

getNetworkBeta <-function( motcorrIn, networkName = 'Default Mode' ) {

  csfAndWM = thresholdImage( boldseg, 1, 1 ) + 
           ( thresholdImage( boldseg, 3, 3 ) %>% iMath("ME",1) )
  ccmat = timeseries2matrix( motcorrIn$moco_img, csfAndWM )
  noiseu = compcor( ccmat, ncompcor = 10 )
  smth = c( 1.0, 1.0, 1.0, 2.0 ) # this is for sigmaInPhysicalCoordinates = F
  simg = smoothImage( motcorrIn$moco_img, smth, sigmaInPhysicalCoordinates = F )
  gmmat = timeseries2matrix( simg, thresholdImage( boldseg, 2, 2 ) )
  tr = antsGetSpacing( bold )[4]
  gmmatf = frequencyFilterfMRI( gmmat, tr = tr, freqLo = 0.01, freqHi = 0.1,  opt = "trig" )
  
  goodtimes = rep( TRUE, dim( motcorrIn$moco_img )[4] )
  goodtimes[ 1:10 ] = FALSE  # signal stabilization
  highMotionTimes = which( motcorrIn$fd$MeanDisplacement >= 0.5 )
  for ( highs in -2:2 ) 
    highMotionTimes = c( highMotionTimes, highMotionTimes + highs )
  highMotionTimes = sort( unique( highMotionTimes ))
  goodtimes[ highMotionTimes ] = FALSE
  
  dfnpts = which( powers_areal_mni_itk$SystemName == networkName ) 
  print( paste(networkName, length(dfnpts)))
  dfnmask = maskImage( ptImg, ptImg, level = dfnpts, binarize = T )
  dfnmat = timeseries2matrix( simg, dfnmask )
  dfnmatf = frequencyFilterfMRI( dfnmat, tr = tr, freqLo = 0.01, freqHi = 0.1,  opt = "trig" )
  dfnsignal = rowMeans( data.matrix( dfnmatf ) )
  locmat = data.matrix( data.frame( gmmatf ))[goodtimes,] 
  dnz = aslDenoiseR( locmat, dfnsignal[goodtimes], covariates = motcorrIn$fd[goodtimes,], 
                     crossvalidationgroups = 8, selectionthresh = 0.2  )
  dfndf = data.frame( signal = dfnsignal, noiseu = noiseu, fd = motcorrIn$fd )
  dfndf = data.frame( signal = dfnsignal[goodtimes], noiseu = dnz$noiseu, fd = dnz$covariates )
  myform = paste( " mat ~ ", paste( names( dfndf ), collapse = "+") )
  dfnmdl = ilr( dfndf, list( mat = locmat ),  myform )
  dfnBetaImg = makeImage(  thresholdImage( boldseg, 2, 2 ),  dfnmdl$tValue["signal",] )
  return( dfnBetaImg )
  }
dfnBetaImgR = getNetworkBeta( motcorr, 'Default Mode' )
dfnBetaImgL = getNetworkBeta( motcorrL, 'Default Mode' )
handR = getNetworkBeta( motcorr, "Sensory/Somatomotor Hand" )
handL = getNetworkBeta( motcorrL, "Sensory/Somatomotor Hand" )
mouthR = getNetworkBeta( motcorr, "Sensory/Somatomotor Mouth" )
mouthL = getNetworkBeta( motcorrL, "Sensory/Somatomotor Mouth" )
mouth = mouthL + mouthR 
hand  = handL + handR
# vizBetaImg = getNetworkBeta( "Visual" )
# salBetaImg = getNetworkBeta( "Salience" )
####################################
##############
```

now we can look at the full continuous beta map for the default mode network

```{r dfnBetas}
plot( und, hand, alpha = 1.0, axis = 3, window.overlay = c(10, max(hand )),
      nslices = 24, ncolumns = 6 )
plot( und, mouth, alpha = 1.0, axis = 3, window.overlay = c(10, max(salBetaImg )),
      nslices = 24, ncolumns = 6 )
plot( und, dfnBetaImgR, alpha = 1.0, axis = 3, window.overlay = c(10, max(dfnBetaImg )),
      nslices = 24, ncolumns = 6 )
ofn = paste0( rdir, "features/LS", id, '_vizBetaImg.nii.gz' )
antsImageWrite( vizBetaImg, ofn )
ofn = paste0( rdir, "features/LS", id, '_dfnBetaImg.nii.gz' )
antsImageWrite( dfnBetaImg, ofn )
ofn = paste0( rdir, "features/LS", id, '_undistort.nii.gz' )
antsImageWrite( und, ofn )
ofn = paste0( rdir, "features/LS", id, '_t1ToBold.nii.gz' )
antsImageWrite( t1toBOLD, ofn )
ofn = paste0( rdir, "features/LS", id, '_mask.nii.gz' )
antsImageWrite( bmask, ofn )
```


Now repeat all of this for the next subject by changing the ID.


# Structural functional joint registration

Finally, use all of this data to do a joint registration using both structural 
and functional features.

```{r poorMansHyperalignment}
# antsRegistration with multivariateExtras
id1 = '2001'
s1f1 = antsImageRead( paste0( rdir, "features/LS", id1, '_dfnBetaImg.nii.gz' ) )
s1f2 = antsImageRead( paste0( rdir, "features/LS", id1, '_undistort.nii.gz' ) )
s1f3 = antsImageRead( paste0( rdir, "features/LS", id1, '_t1ToBold.nii.gz' ) )
s1fv = antsImageRead( paste0( rdir, "features/LS", id1, '_vizBetaImg.nii.gz' ) )
s1mask = antsImageRead( paste0( rdir, "features/LS", id1, '_mask.nii.gz' ) )
id2 = '3026'
s2f1 = antsImageRead( paste0( rdir, "features/LS", id2, '_dfnBetaImg.nii.gz' ) )
s2f2 = antsImageRead( paste0( rdir, "features/LS", id2, '_undistort.nii.gz' ) )
s2f3 = antsImageRead( paste0( rdir, "features/LS", id2, '_t1ToBold.nii.gz' ) )
s2fv = antsImageRead( paste0( rdir, "features/LS", id2, '_vizBetaImg.nii.gz' ) )
s2mask = antsImageRead( paste0( rdir, "features/LS", id2, '_mask.nii.gz' ) )
#############
jrig = antsRegistration( s1f3 * s1mask, s2f3  * s2mask, "Affine"  )
ureg = antsRegistration( s1f3, s2f3, "SyNOnly", initialTransform = jrig$fwd,  mask = s1mask )
jreg = antsRegistration( s1f3, s2f3, "SyNOnly", initialTransform = jrig$fwd,  mask = s1mask,
  multivariateExtras = list(
   list( "mattes", s1fv, s2fv, 1, 32 ),
   list( "mattes", s1f1, s2f1, 1, 32 ) ), verbose = FALSE )
#############
vizWarped = antsApplyTransforms( s1f1, s2fv, ureg$fwdtransforms )
metric = antsrMetricCreate( s1fv, vizWarped, type="Correlation" )
strWarped = antsApplyTransforms( s1f1, s2f3, ureg$fwdtransforms )
smetric = antsrMetricCreate( s1f3, strWarped, type="Correlation" )
print( paste("univar-dfn", antsrMetricGetValue( metric ), 'str', antsrMetricGetValue( smetric ) ) )
#############
dfnWarped = antsApplyTransforms( s1f1, s2f1, jreg$fwdtransforms )
vizWarped = antsApplyTransforms( s1f1, s2fv, jreg$fwdtransforms )
metric = antsrMetricCreate( s1fv, vizWarped, type="Correlation" )
strWarped = antsApplyTransforms( s1f1, s2f3, jreg$fwdtransforms )
smetric = antsrMetricCreate( s1f3, strWarped, type="Correlation" )
print( paste("mulvar-dfn", antsrMetricGetValue( metric ), 'str', antsrMetricGetValue( smetric ) ) )
#############
```

Result:  *the joint registration performs better on both structural and functional metrics* 
as measured by correlation of the features (not ideal).

Visualize the "fixed" subject and DFN first.

Then show the "deformed" subject and DFN second.

```{r regviz}
plot( s1f3, s1f1, alpha = 1.0, axis = 3, window.overlay = c(3, max(dfnBetaImg )),
      nslices = 24, ncolumns = 6, doCropping=FALSE )
plot( strWarped, dfnWarped, alpha = 1.0, axis = 3, window.overlay = c(3, max(dfnBetaImg )),
      nslices = 24, ncolumns = 6, doCropping=FALSE  )
```
